{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df45521f",
   "metadata": {},
   "source": [
    "# **GRUPO N° 2**\n",
    "\n",
    "### Materia LABORATORIO 2\n",
    "\n",
    "### Profesores\n",
    "#### 1) Andres Javier ARANEO\n",
    "#### 2) Tomas LANZA\n",
    "\n",
    "### Alumnos\n",
    "#### 1) Leandro BOISSELIER\n",
    "#### 2) Juan CZYRKA\n",
    "#### 3) Pablo CABRAL\n",
    "#### 4) Franco SONZOGNI\n",
    "\n",
    "### Repositorio\n",
    "#### [Repositorio Grupo 2] https://github.com/lmbsoft/mcd24-labo2/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13d4436",
   "metadata": {},
   "source": [
    "# **CASO**\n",
    "\n",
    "Esta solución busca predecir la rapidez con la que se adoptará una mascota, basándose en datos tabulares, descripciones y fotos. El objetivo es entregar herramientas que ayuden a refugios y rescatistas a mejorar los perfiles de sus mascotas, aumentando las posibilidades de adopción y reduciendo el sufrimiento animal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb27b95",
   "metadata": {
    "papermill": {
     "duration": 0.012333,
     "end_time": "2021-12-03T23:56:04.751065",
     "exception": false,
     "start_time": "2021-12-03T23:56:04.738732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Importar las Librerías Necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b297f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las librerías usadas en los distintos procesos que ejecutamos a lo largo del desarrollo fueron:\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import WordCloud\n",
    "import TextBlob\n",
    "import sklearn\n",
    "import json\n",
    "import nltk\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import joblib\n",
    "# Librería provista por los profesores para poder generar una matriz de confusión custom.\n",
    "from UA_MDM_LDI_II.tutoriales.utils import plot_confusion_matrix\n",
    "import torch\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import datetime\n",
    "import tqdm\n",
    "import torchvision\n",
    "import utils\n",
    "from augment.autoaugment import ImageNetPolicy\n",
    "from augment.cutout import Cutout\n",
    "import gc\n",
    "from plotly import express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f7562c",
   "metadata": {
    "papermill": {
     "duration": 0.010577,
     "end_time": "2021-12-03T23:56:04.810013",
     "exception": false,
     "start_time": "2021-12-03T23:56:04.799436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Leer los Datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb3642",
   "metadata": {},
   "source": [
    "## Los datos de partida para iniciar el proceso, son los provistos mediane la plataforma Kaggle.\n",
    "\n",
    "### Descripciones de archivos\n",
    "1) **train.csv**: datos tabulares/de texto para el conjunto de entrenamiento\n",
    "2) **breed_labels.csv**: contiene el tipo y el nombre de la raza para cada BreedID. El tipo 1 es perro y el 2 es gato.\n",
    "3) **color_labels.csv**: contiene el nombre del color para cada ID del color\n",
    "4) **state_labels.csv**: contiene el nombre del estado para cada ID de estado\n",
    "\n",
    "### Adicional a estos datos tabulares se nos provee de la siguiente información estructurada y semiestructurada (json):\n",
    "\n",
    "1) Imágenes\n",
    "En el caso de las mascotas que tengan fotos, tenemos un set de archivos provistos por Kaggle en el formato \"PetID-ImageNumber.jpg\". Siempre la imagen 1 es la foto de perfil (predeterminada) establecida para la mascota. Por motivos de privacidad, se han ocultado los rostros, los números de teléfono y los correos electrónicos.\n",
    "\n",
    "2) Metadatos de la imagen\n",
    "\n",
    "    Hemos procesado las imágenes a través de la API Vision de Google, lo que nos proporciona un análisis de anotaciones faciales, anotaciones de etiquetas, anotaciones de texto y propiedades de la imagen.\n",
    "\n",
    "    Algunas propiedades no existirán en el archivo JSON si no están presentes, por ejemplo, la anotación de rostros. La anotación de texto se ha simplificado a solo una entrada de la descripción de texto completa (en lugar del resultado JSON detallado desglosado por caracteres y palabras individuales). Los números de teléfono y los correos electrónicos ya están anonimizados en la anotación de texto.\n",
    "\n",
    "    Referencia de la API de Google Vision:\n",
    "    https://cloud.google.com/vision/docs/reference/rest/v1/images/annotate\n",
    "\n",
    "3) Datos de sentimientos\n",
    "    Hemos ejecutado la descripción de cada perfil de mascota a través de la API de lenguaje natural de Google, lo que proporciona un análisis de sentimientos y entidades clave. Utilizamos esta información complementaria para el análisis de la descripción de la mascota. Algunas descripciones la API no las pudo analizar. Por lo tanto, encontramos menos archivos de sentimientos que filas en el conjunto de datos.\n",
    "\n",
    "    El formato del nombre del archivo es PetID.json .\n",
    "\n",
    "    Referencia de la API de lenguaje natural de Google:\n",
    "    https://cloud.google.com/natural-language/docs/basics\n",
    "\n",
    "\n",
    "### En la medida que el proceso avanza, fuimos creando nuevos lotes de datos. Estos son:\n",
    "\n",
    "1) **train_data_ext.csv** --> Agrega nuevos atributos calculados.\n",
    "2) **train_data_fe.csv** --> Agrega nuevos atrivutos mediante diferentes métodos de Feature Engineering.\n",
    "3) **train_data_fe_cleaned.csv** --> Realiza ajustes sobre los nuevos features.\n",
    "4) **train_data_fe_text_llm.csv** --> Agrega features obtenidos mediante técnicas de LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6efe8e",
   "metadata": {},
   "source": [
    "## 3. Proceso\n",
    "\n",
    "### Nuestro proceso de trabajo se puede seguir desde los siguientes notebooks:\n",
    "\n",
    "####    1) Flujo inicia en el EDA: **grupo2-EDA-ii.ipynb**\n",
    "https://github.com/lmbsoft/mcd24-labo2/blob/main/grupo2-EDA-ii.ipynb\n",
    "####    1b) Proceso de extracción de características mediante LLM:  **01_FE_llms_ollama.ipynb** (Se corre por única vez, dado que el tiempo de procesamiento lleva +de 8 hs y no es necesario reprocesar cada vez que re entrenamos el modelo)\n",
    "https://github.com/lmbsoft/mcd24-labo2/blob/main/01_FE_llms_ollama.ipynb\n",
    "####    2) Proceso de FE: **grupo2-FE.ipynb**\n",
    "https://github.com/lmbsoft/mcd24-labo2/blob/main/grupo2-FE.ipynb\n",
    "####    3) Entrenamiento de tabulares: **grupo2-Train-Tabulares.ipynb**\n",
    "https://github.com/lmbsoft/mcd24-labo2/blob/main/grupo2-Train-Tabulares.ipynb\n",
    "####    4) Entrenamiento resnet: **grupo2-Resnet50_3_train_augment.ipynb**\n",
    "https://github.com/lmbsoft/mcd24-labo2/blob/main/grupo2-Resnet50_3_train_augment.ipynb\n",
    "####    5) Integración / Ensamble de modelos: **grupo2-Resnet50_2_integrar_fe.ipynb**\n",
    "https://github.com/lmbsoft/mcd24-labo2/blob/main/grupo2-Resnet50_2_integrar_fe.ipynb\n",
    "\n",
    "\n",
    "### CONSIDERACIONES FINALES\n",
    "Agregar el texto en el caso de que aplique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def7e919",
   "metadata": {
    "papermill": {
     "duration": 0.010706,
     "end_time": "2021-12-03T23:56:04.853250",
     "exception": false,
     "start_time": "2021-12-03T23:56:04.842544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. EDA y Pre Procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3565a5",
   "metadata": {},
   "source": [
    "### Pasos Ejecutados:\n",
    "#### 1) Carga de Datos:\n",
    "        Cargamos los archivos train.csv, StateLabels.csv, ColorLabels.csv y BreedLabels.csv.\n",
    "        Mostramos las primeras filas de cada archivo para verificar su contenido.\n",
    "\n",
    "#### 2) Revisión de Datos Faltantes:\n",
    "        Calculamos los valores faltantes y su porcentaje en el dataset de entrenamiento.\n",
    "\n",
    "#### 3) Análisis exploratorio general de Variables Categóricas:\n",
    "        Realizamos gráficos de conteo para variables categóricas como Type, Gender, Color1, Color2, Color3, MaturitySize, FurLength, Vaccinated, Dewormed, Sterilized, Health, State.\n",
    "\n",
    "#### 4) Análisis exploratorio general de Variables Numéricas:\n",
    "        Realizamos histogramas para variables numéricas como Age, Quantity, Fee, VideoAmt, PhotoAmt.\n",
    "\n",
    "#### 5) Análisis de Correlación:\n",
    "        Calculamos y visualizamos las correlaciones entre las variables numéricas y AdoptionSpeed.\n",
    "        Identificamos las palabras más positivamente y negativamente correlacionadas con AdoptionSpeed utilizando funciones de la librería TF-IDF.\n",
    "\n",
    "#### 6) Creación de Nuevas Características:\n",
    "        Creamos nuevas características basadas en la presencia de palabras importantes en la descripción de las mascotas.\n",
    "\n",
    "#### 7) Visualización de la Presencia de Palabras:\n",
    "        Realizamos boxplots para visualizar la presencia de palabras importantes por tipo de mascota y AdoptionSpeed.\n",
    "\n",
    "### CONSIDERACIONES FINALES\n",
    "\n",
    "#### Sobre Datos faltantes\n",
    "Encontramos datos faltantes en la columna nombre, esto por lo que vimos está asociado a los casos en donde el registro describe a una población de mascotas, a casos donde se desconoce el nombre o donde la mascota es un cachorro y probablemente se busca que el potencial nuevo propietario pueda definir su nombre. **En el grupo decidimos no hacer ningún tipo de transformación sobre estos faltantes.**\n",
    "\n",
    "#### Outliers\n",
    "Para abordar la problemática de valores atípicos consideramos diferentes técnicas, y terminamos seleccionando la opción que nos ofrece la robustez implícita que tiene el modelo de LGBM.\n",
    "\n",
    "#### Lematización\n",
    "Aplicamos NLTK + TFIDF para analizar la correlación de lemas con la clase target. El resultado del análisis lo aplicamos en el proceso de FE.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97afe8c4",
   "metadata": {
    "papermill": {
     "duration": 0.010497,
     "end_time": "2021-12-03T23:56:04.941880",
     "exception": false,
     "start_time": "2021-12-03T23:56:04.931383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Feature Engeneering mediante la aplicación de LLM\n",
    "    https://github.com/lmbsoft/mcd24-labo2/blob/main/01_FE_llms_ollama.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083fe7b8",
   "metadata": {},
   "source": [
    "### Pasos Ejecutados:\n",
    "\n",
    "#### 1) Unión de Datos con Etiquetas:\n",
    "        Unimos los datos de train.csv con las etiquetas de razas, colores y estados.\n",
    "\n",
    "#### 2) Mapeo de Valores Numéricos a Descripciones:\n",
    "        Creamos diccionarios para mapear valores numéricos a descripciones textuales para las variables Gender, MaturitySize, FurLength, Vaccinated, Dewormed, Sterilized y Health.\n",
    "\n",
    "#### 3) Análisis de Coherencia:\n",
    "        Definimos una función para generar preguntas y obtener respuestas de coherencia utilizando ollama.\n",
    "\n",
    "#### 4) Aplicación del Análisis de Coherencia:\n",
    "        Definimos una función para aplicar el análisis de coherencia a todo el dataset.\n",
    "\n",
    "#### 5) Aplicación del Análisis de Coherencia al Dataset:\n",
    "        Aplicamos el análisis de coherencia al dataset extendido.\n",
    "\n",
    "### Se guardó el nuevo dataset con las características de coherencia en un archivo CSV.\n",
    "\n",
    "### CONSIDERACIONES FINALES\n",
    "\n",
    "En este primer proceso de FE aplicamos modelos de LLM para crear nuevas características relacionadas con la coherencia de la descripción y los datos tabulares. También generamos características que buscan obtener clasificaciones tabuladas para lograr una mejor descripción del individuo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2541b3a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:53:19.438974Z",
     "iopub.status.busy": "2021-12-03T23:53:19.437663Z",
     "iopub.status.idle": "2021-12-03T23:53:19.464612Z",
     "shell.execute_reply": "2021-12-03T23:53:19.463582Z",
     "shell.execute_reply.started": "2021-12-03T23:53:19.438721Z"
    },
    "papermill": {
     "duration": 0.010467,
     "end_time": "2021-12-03T23:56:04.984489",
     "exception": false,
     "start_time": "2021-12-03T23:56:04.974022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5b. Feature Engeneering\n",
    "    https://github.com/lmbsoft/mcd24-labo2/blob/main/grupo2-FE.ipynb\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee22045c",
   "metadata": {},
   "source": [
    "### Pasos Ejecutados:\n",
    "\n",
    "#### 1) Creación de nuevas características:\n",
    "        Creamos nuevas características producto del análisis de EDA. Estas se fundan en diferentes aspectos, como: Correlaciones con la velocidad de adopción. Correlaciones entre atributos que agrupan características similares (SALUD), agrupación de atributos que describen aspectos de las mascotas como color y raza.\n",
    "\n",
    "#### 2) Limpieza y Normalización de Texto:\n",
    "        Aplicamos funciones para limpiar y normalizar los textos de las descripciones de las mascotas. Posteriormente trabajamos sobre el análisis de sentimiento que encontramos en los archivos Json procesados mediante la API de Google.\n",
    "        También se aplican técnicas de lematización para realizar cruces entre la frecuencia de las palabras y la velocidad de adopción y creamos nuevos atributos.\n",
    "\n",
    "#### 3) Análisis de Coherencia:\n",
    "        Implementamos un análisis de coherencia utilizando un modelo LLM (phi3 de ollama) para evaluar descripciones y características. Ver ítem anterior.\n",
    "\n",
    "Enfocamos la exploración de datos y la ingeniería de características en enriquecer el dataset con información descriptiva de razas, colores y características geográficas y demográficas de los estados en los cuales se encuentran los refugios. Creamos nuevas características como por ejemplo \"IsPureBreed\", \"Overall_Health\", etc. \n",
    "Finalmente realizamos un merge con las características del análisis de coherencia de las descripciones de las mascotas, lo cual, a nuestro entender mejora significativamente la calidad y utilidad del dataset. ​\n",
    "\n",
    "### CONSIDERACIONES FINALES\n",
    "Sumamos las siguientes características manuales y luego del análisis EDA:\n",
    "\n",
    "   - `IsPureBreed`: Indica si la mascota es de raza pura.\n",
    "   - `AgeInYears`: Edad de la mascota en años.\n",
    "   - `Healthy`: Indica si la mascota está en buenas condiciones de salud.\n",
    "   - `Overall_Health` : Un indicador categórico de las condiciones de salud\n",
    "   - `IsFree`: Indica si la adopción es gratuita.\n",
    "   - `Breed1_Rarity`: Rareza de la raza primaria.\n",
    "   - `ColorQuantity`: Cantidad de colores\n",
    "   - `TotalMedia`: Cantidad de imágenes y videos\n",
    "   - `StatePopulation`: Población aproximada del estado.\n",
    "   - `IsPeninsular`: Indica si el estado es peninsular.\n",
    "   - `QuantityCategory`: Categoría de la cantidad de animales en la publicación.\n",
    "   - `QuantityLog`: Transformación logarítmica de la cantidad de animales.\n",
    "\n",
    "Sumamos las siguientes características desde el proceso de análisis de sentimiento que describimos en la notebook **grupo2-FE**:\n",
    "\n",
    "   - 'SentimentMagnitude'\n",
    "   - 'SentimentScore'\n",
    "   - 'SentimentLanguage'\n",
    "   - 'SentimentInterpretation'\n",
    "\n",
    "En el grupo decidimos dejar todas estas características luego de realizar un análisis de feature importance, en el cual vimos que tienen impacto en la construcción del modelo final.\n",
    "\n",
    "![Feature Importance Team 2](https://drive.google.com/uc?id=1yZ2XAGDeVa6G4JYhMoME_FOrzUxtgqgQ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9c39d",
   "metadata": {
    "papermill": {
     "duration": 0.0107,
     "end_time": "2021-12-03T23:56:05.027425",
     "exception": false,
     "start_time": "2021-12-03T23:56:05.016725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Modelado predictivo usando **\"LightGBM\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffdaf5",
   "metadata": {},
   "source": [
    "### El proceso de modelado predictivo incluyó la carga y preparación de datos, optimización de hiperparámetros con Optuna, entrenamiento y evaluación de modelos LightGBM, y tratamos de identificar los mejores resultados, buscamos darle un enfoque riguroso y lo mas detallado posible. Intentamos obtener modelos de alta precisión y minimizar el overfitting, asumiendo la complejidad que esto representa.\n",
    "\n",
    "### El proceso aplicado fue el siguiente:\n",
    "\n",
    "#### 1) División de Datos en Entrenamiento y Prueba:\n",
    "        Dividimos los datos en conjuntos de entrenamiento y prueba utilizando train_test_split.\n",
    "\n",
    "#### 2) Definición de Funciones de Evaluación y Objetivo:\n",
    "        Definimos funciones de evaluación como **cohen_kappa_score, accuracy_score y balanced_accuracy_score**.\n",
    "        Cionfiguramos la función objetivo para Optuna, que incluye el entrenamiento del modelo y la evaluación del rendimiento utilizando Kappa cuadrática.\n",
    "\n",
    "#### 3) Configuración y Ejecución de Optuna para la Optimización de Hiperparámetros:\n",
    "        Creamos un estudio de Optuna para la optimización de hiperparámetros del modelo LightGBM.\n",
    "        Definimos el almacenamiento de artefactos de Optuna y ejecutamos la búsqueda de los mejores hiperparámetros.\n",
    "\n",
    "#### 4) Entrenamiento del Modelo:\n",
    "        Entrenamos el modelo con los mejores hiperparámetros utilizando un esquema de **validación cruzada StratifiedKFold**.\n",
    "\n",
    "#### 5) Evaluación del Modelo:\n",
    "        Evaluamos el modelo en los conjuntos de entrenamiento y prueba, calculando métricas como Kappa cuadrática, precisión, precisión balanceada y reporte de clasificación.\n",
    "        Agregamos las matrices de confusión para analizar y entender el rendimiento.\n",
    "\n",
    "#### 6) Almacenamiento de Resultados:\n",
    "        Alamacenamos los resultados de cada fold en un DataFrame, incluyendo las métricas de evaluación y aspectos relacionados al overfitting.\n",
    "        Ordenamos y mostramos los resultados para identificar los mejores modelos.\n",
    "\n",
    "#### 7) Análisis de los Mejores Trials de Optuna:\n",
    "        Extraemos y analizamos los 30 mejores trials de Optuna, entrenando y evaluando modelos con los mejores hiperparámetros.\n",
    "        Imprimimos los resultados de los mejores trials para comparación.\n",
    "\n",
    "### CONSIDERACIONES FINALES\n",
    "La primer ejecución del entrenamiento utilizando los valores baseline de hiperparámetros nos arrojó un índice de Kappa: **0.335**\n",
    "A continuación ejecutamos varios estudios con optuna, analizamos los rendiminetos y finalmente nos quedamos con el estudio llamado **\"05 - LGB Multiclass CV 06\"**\n",
    "El modelo final, con optimización de hiperparámetros mediante optuna nos arrojó en train un Kappa de: **0.384**\n",
    "Este mismos modelo en test nos da un Kappa de: **0.331**\n",
    "La matriz de confusión nos indica que el modelo en general tiene mayor precisión para predecir la **clase 4**, una presición aceptable para las clases **1,2 y 3** y no se logran mejoras para la **clase 0**.\n",
    "En resumen, pensando en el modelo de negocio, consideramos que es válido que el modelo tenga una mejor presición para los individuos que permanecen mas tiempo en el refugio.\n",
    "En el análisis de feature importance observamos que las características agregadas en el proceso de FE tuvieron un muy buen Score. Por ejemplo:\n",
    "\n",
    "- Breed1_Rarity\n",
    "- TotalMedia\n",
    "- StatePopulation\n",
    "- Is_Calm\n",
    "- Contains_Adoption\n",
    "\n",
    "La característica de mayor score es:\n",
    "\n",
    "- SentimentMagnitude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1249152",
   "metadata": {
    "papermill": {
     "duration": 0.012977,
     "end_time": "2021-12-03T23:56:05.099771",
     "exception": false,
     "start_time": "2021-12-03T23:56:05.086794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Modelado en base a imágenes (Datos no estructurados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf259c3",
   "metadata": {},
   "source": [
    "### En este proceso de entrenamiento en el cual procesamos las imágenes asociadas a las mascotas, aplicamos redes neuronales y esto involucró la carga y configuración de un modelo **ResNet50 preentrenado**, usamos técnicas de aumento de datos, optimizamos hiperparámetros utilizando Optuna, y gestionamos recursos de GPU, asegurando así un entrenamiento optimizado para la clasificación de imágenes.\n",
    "\n",
    "### El proceso aplicado es el siguiente:\n",
    "\n",
    "#### 1) Verificación de Disponibilidad de GPU:\n",
    "        Comprobamos de la disponibilidad de GPU para el entrenamiento.\n",
    "\n",
    "#### 2) Importación de Librerías:\n",
    "        Importamos las librerías esenciales para el manejo de datos, modelos, optimización y visualización, incluyendo torch, optuna, sklearn y joblib.\n",
    "\n",
    "#### 3) Instalación de Paquetes Necesarios:\n",
    "        Instalación del paquete kaleido para visualización.\n",
    "\n",
    "#### 4) Carga y Configuración del Modelo:\n",
    "        Importamos el modelo preentrenado ResNet50.\n",
    "        Modificamos la última capa para adaptarse a la clasificación de 5 clases.\n",
    "        Configuramos el dispositivo para usar CUDA si está disponible.\n",
    "        Definimos el criterio de pérdida como CrossEntropyLoss.\n",
    "        Configuramos el optimizador SGD con parámetros de learning rate y momentum.\n",
    "\n",
    "#### 5) Definición de Transformaciones y Data Augmentation:\n",
    "        Definición de transformaciones para aumentar el dataset, incluyendo políticas de AutoAugment y Cutout.\n",
    "\n",
    "#### 6) Carga y División de Datos:\n",
    "        Cargamos los datos de entrenamiento y validación, y aplicación de las transformaciones definidas.\n",
    "        Dividimos los datos en conjuntos de entrenamiento y validación.\n",
    "\n",
    "#### 7) Definición de la Función de Entrenamiento:\n",
    "        Implementamos una función para entrenar y validar el modelo, incluyendo la configuración del optimizador y el ciclo de entrenamiento.\n",
    "\n",
    "#### 8) Entrenamiento del Modelo:\n",
    "        Ejecutamos el entrenamiento del modelo con los datos cargados y transformados.\n",
    "        Guardamos del mejor modelo encontrado durante el entrenamiento.\n",
    "\n",
    "#### 9) Optimización de Hiperparámetros con Optuna:\n",
    "        Definimos la función de entrenamiento para Optuna, sugiriendo valores para epochs, learning rate y momentum.\n",
    "        Creamos y ejecutamos el estudio de Optuna para optimizar los hiperparámetros del modelo.\n",
    "\n",
    "### CONSIDERACIONES FINALES\n",
    "- Hicimnos un primer exprimento sin perturbar las imágenes y obtuvimos un Kappa de: **0.293**\n",
    "- Posterioremente aplicamos una perturbación de las imágenes durante el entrenamiento y logramos un Kappa de: **0.333**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1eaa32",
   "metadata": {},
   "source": [
    "## 8. Desarrollar modelo ensamblado (Opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078c82a",
   "metadata": {},
   "source": [
    "### Mediante este proceso de ensamblaje de modelos, buscamos combinar de forma efectiva las predicciones de **LightGBM (basado en datos tabulares)** y **ResNet (basado en imágenes)** para mejorar la precisión de la predicción. Pretendemos aprovechar las fortalezas de ambos enfoques, y utilizamos matrices de confusión y el coeficiente de Kappa cuadrática para analizar y verificar si obtenemos mejoras en la precisión del modelo combinado.\n",
    "\n",
    "### El proceso aplicado es el siguiente:\n",
    "\n",
    "#### 1) Carga de Estudios de Optuna:\n",
    "        Tomamos los estudios de Optuna para los modelos LightGBM y ResNet previamente optimizados y guardados.\n",
    "\n",
    "#### 2) Carga de Resultados de Modelos:\n",
    "        Cargamos los resultados de predicción de los modelos LightGBM y ResNet desde los artefactos de Optuna.\n",
    "\n",
    "#### 3) Fusión de Resultados:\n",
    "        Fusionamos los resultados de predicción de ambos modelos en un solo DataFrame.\n",
    "        Renombramos columnas para claridad (lgb_pred_score y resnet_pred_score).\n",
    "\n",
    "#### 4) Manejo de Valores Nulos:\n",
    "        Reemplazamos valores nulos en las predicciones del modelo ResNet con vectores de ceros.\n",
    "\n",
    "#### 5) Cálculo de Predicciones Combinadas:\n",
    "        Calculamos las puntuaciones combinadas (blend_pred_score) sumando las predicciones de LightGBM y ResNet.\n",
    "\n",
    "#### 6) Determinación de Clases Predichas:\n",
    "        Determinamos las clases predichas para cada modelo (lgb_pred y resnet_pred) y para la combinación de ambos (blended_pred).\n",
    "\n",
    "#### 7) Visualización de Matrices de Confusión:\n",
    "        Visualizamos las matrices de confusión para evaluar el rendimiento de los modelos individuales y del modelo combinado.\n",
    "        Cálculamos y visualizamos el coeficiente de Kappa cuadrática para cada conjunto de predicciones.\n",
    "\n",
    "### CONSIDERACIONES FINALES\n",
    "Para las puntuaciones combinadas usamos la estrategia de suma de las puntuaciones de predicción de ambos modelos para cada clase y selecciona la clase con la puntuación más alta como la predicción final.\n",
    "El valor de Kappa obtenido para el modelo ensamblado es de: **0.336**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee8310",
   "metadata": {},
   "source": [
    "## 9. Valoración del modelo/conclusiones\n",
    "\n",
    "1) Observamos que el ensamble del modelo tabular con el de imágenes nos permitió obtener una mejora en le índice de Kappa en comparación a los modelos individuales.\n",
    "2) Pudimos comprobar durante la experimentación, tanto en el modelo tabular como el de imágenes que aplicando estrategias de FE como la selección de umbrales de busqueda para optimizar HP va aportando mejoras en el rendimiento de los modelos.\n",
    "3) También pudimos comprobar que al incluir perturbaciones en las imágenes procesadas por el modelo resnet logramos mejores rendimientos.\n",
    "4) Podemos concluir que si bien el modelo final ensamblado no logró un valor de Kappa alto (menor a 0.6), el mismo es aceptable para este caso de negocio.\n",
    "5) Confiamos que todas las técnicas aprendidas nos aportarán mayores herramientas para afrontar los desafíos del futuro en el campos de la ciencia de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59822921",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.27613,
   "end_time": "2021-12-03T23:56:05.761994",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-03T23:55:54.485864",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
